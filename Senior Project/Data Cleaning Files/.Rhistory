library(corrplot)
# For Imputing
library(mice)
library(missForest)
library(VIM)
library(softImpute)
library(ggplot2)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Split data before imputing
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
df_11_12 <- read.csv("Cleaned Data/11_12_cleaned.csv")
df_11_12$Year <- c(1)
df_13_14 <- read.csv("Cleaned Data/13_14_cleaned.csv")
df_13_14$Year <- c(2)
df_15_16 <- read.csv("Cleaned Data/15_16_cleaned.csv")
df_15_16$Year <- c(3)
df_17_18 <- read.csv("Cleaned Data/17_18_cleaned.csv")
df_17_18$Year <- c(4)
# Combine all Data
full_df <- bind_rows(df_11_12, df_13_14, df_15_16, df_17_18)
full_df$X <- NULL
# Factoring the outcome/target variable
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
levels(full_df$NegOutcome) <- c("Non-Negative", "Negative")
ML_df <- full_df %>%
select(Race2, Race1, Sex, Age, Diabetes, BPMed, Smoking, TotalChol, HDLChol, AvgSysBP, LowCost, FastFood, BalancedMeals, FoodSecurity, Ann_HHIncome, Ann_FamIncome, PovertyRatio, NegOutcome)
# Count NAs each column
na_counts <- colSums(is.na(ML_df))
print(na_counts)
# Barplot showing null values
# Convert to dataframe for plotting
na_data <- as.data.frame(na_counts)
na_data$Column <- rownames(na_data)
names(na_data) <- c("NA_Count", "Column")
ggplot(na_data, aes(x = reorder(Column, NA_Count), y = NA_Count)) +
geom_bar(stat = "identity", fill = "tomato") +
theme_minimal() +
labs(title = "Missing Values in Each Column", x = "Column", y = "Number of Missing Values") +
coord_flip() # Use coord_flip() to make the plot horizontal
## Plotting the target feature
ggplot(ML_df, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Negative CVD Outcome", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table <- table(full_df$NegOutcome)
print(count_table)
# Calculate the percentage for each category
percentages <- prop.table(count_table) * 100
print(percentages)
# Splitting the Data
set.seed(1)
split <- initial_split(ML_df, prop = 0.75, strata = "NegOutcome")
# 75%-25% split
df_train <- training(split)
df_test <- testing(split)
## Plotting the target feature
ggplot(df_train, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Training", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_train <- table(df_train$NegOutcome)
print(count_table_train)
# Calculate the percentage for each category
percentages_train <- prop.table(count_table_train) * 100
print(percentages_train)
## Plotting the target feature
ggplot(df_test, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Testing", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_test <- table(df_test$NegOutcome)
print(count_table_test)
# Calculate the percentage for each category
percentages_test <- prop.table(count_table_test) * 100
print(percentages_test)
# Load in Libraries
library(NHANES)
library(dplyr)
library(haven)
library(tidyverse)
library(caret)
library(tidymodels)
library(tidyverse)
library(readr)
library(corrplot)
library(CVrisk)
# For Imputing
library(mice)
library(missForest)
library(VIM)
library(softImpute)
library(ggplot2)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Split data before imputing
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
df_11_12 <- read.csv("Cleaned Data/11_12_cleaned.csv")
df_11_12$Year <- c(1)
df_13_14 <- read.csv("Cleaned Data/13_14_cleaned.csv")
df_13_14$Year <- c(2)
df_15_16 <- read.csv("Cleaned Data/15_16_cleaned.csv")
df_15_16$Year <- c(3)
df_17_18 <- read.csv("Cleaned Data/17_18_cleaned.csv")
df_17_18$Year <- c(4)
# Combine all Data
full_df <- bind_rows(df_11_12, df_13_14, df_15_16, df_17_18)
full_df$X <- NULL
# Factoring the outcome/target variable
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
levels(full_df$NegOutcome) <- c("Non-Negative", "Negative")
# Count NAs each column
na_counts <- colSums(is.na(full_df))
print(na_counts)
# Barplot showing null values
# Convert to dataframe for plotting
na_data <- as.data.frame(na_counts)
na_data$Column <- rownames(na_data)
names(na_data) <- c("NA_Count", "Column")
ggplot(na_data, aes(x = reorder(Column, NA_Count), y = NA_Count)) +
geom_bar(stat = "identity", fill = "tomato") +
theme_minimal() +
labs(title = "Missing Values in Each Column", x = "Column", y = "Number of Missing Values") +
coord_flip() # Use coord_flip() to make the plot horizontal
## Plotting the target feature
ggplot(full_df, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Negative CVD Outcome", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table <- table(full_df$NegOutcome)
print(count_table)
# Calculate the percentage for each category
percentages <- prop.table(count_table) * 100
print(percentages)
# Splitting the Data
set.seed(1)
split <- initial_split(full_df, prop = 0.75, strata = "NegOutcome")
# 75%-25% split
df_train <- training(split)
df_test <- testing(split)
## Plotting the target feature
ggplot(df_train, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Training", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_train <- table(df_train$NegOutcome)
print(count_table_train)
# Calculate the percentage for each category
percentages_train <- prop.table(count_table_train) * 100
print(percentages_train)
## Plotting the target feature
ggplot(df_test, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Testing", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_test <- table(df_test$NegOutcome)
print(count_table_test)
# Calculate the percentage for each category
percentages_test <- prop.table(count_table_test) * 100
print(percentages_test)
View(full_df)
# Impute Rest of Missing Data
imputation_fun_mice <- function(df, target){
init <- mice(df, maxit=0, remove.collinear = FALSE, remove.constant = FALSE)
# Ensure the target variable is not imputed
init$method[target] <- ""
imputed <- mice(df, method=init$method, predictorMatrix=init$predictorMatrix, m=5, nnet.MaxNWts = 5000, remove.collinear = FALSE, remove.constant = FALSE)
completed <- mice::complete(imputed)
return(completed)
}
imputed_train <- imputation_fun_mice(df_train, "NegOutcome")
imputed_test <- imputation_fun_mice(df_test, "NegOutcome")
# Count NAs each column to make sure imputation worked
colSums(is.na(imputed_train))
colSums(is.na(imputed_test))
View(imputed_train)
# Load in Libraries
library(NHANES)
library(dplyr)
library(haven)
library(tidyverse)
library(caret)
library(tidymodels)
library(tidyverse)
library(readr)
library(corrplot)
library(CVrisk)
# For Imputing
library(mice)
library(missForest)
library(VIM)
library(softImpute)
library(ggplot2)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Split data before imputing
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
df_11_12 <- read.csv("Cleaned Data/11_12_cleaned.csv")
df_11_12$Year <- c(1)
df_13_14 <- read.csv("Cleaned Data/13_14_cleaned.csv")
df_13_14$Year <- c(2)
df_15_16 <- read.csv("Cleaned Data/15_16_cleaned.csv")
df_15_16$Year <- c(3)
df_17_18 <- read.csv("Cleaned Data/17_18_cleaned.csv")
df_17_18$Year <- c(4)
# Combine all Data
full_df <- bind_rows(df_11_12, df_13_14, df_15_16, df_17_18)
full_df$X <- NULL
# Factoring the outcome/target variable
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
levels(full_df$NegOutcome) <- c("Non-Negative", "Negative")
# Count NAs each column
na_counts <- colSums(is.na(full_df))
print(na_counts)
# Barplot showing null values
# Convert to dataframe for plotting
na_data <- as.data.frame(na_counts)
na_data$Column <- rownames(na_data)
names(na_data) <- c("NA_Count", "Column")
ggplot(na_data, aes(x = reorder(Column, NA_Count), y = NA_Count)) +
geom_bar(stat = "identity", fill = "tomato") +
theme_minimal() +
labs(title = "Missing Values in Each Column", x = "Column", y = "Number of Missing Values") +
coord_flip() # Use coord_flip() to make the plot horizontal
## Plotting the target feature
ggplot(full_df, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Negative CVD Outcome", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table <- table(full_df$NegOutcome)
print(count_table)
# Calculate the percentage for each category
percentages <- prop.table(count_table) * 100
print(percentages)
# Splitting the Data
set.seed(1)
split <- initial_split(full_df, prop = 0.75, strata = "NegOutcome")
# 75%-25% split
df_train <- training(split)
df_test <- testing(split)
## Plotting the target feature
ggplot(df_train, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Training", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_train <- table(df_train$NegOutcome)
print(count_table_train)
# Calculate the percentage for each category
percentages_train <- prop.table(count_table_train) * 100
print(percentages_train)
## Plotting the target feature
ggplot(df_test, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Testing", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_test <- table(df_test$NegOutcome)
print(count_table_test)
# Calculate the percentage for each category
percentages_test <- prop.table(count_table_test) * 100
print(percentages_test)
# Impute Rest of Missing Data
imputation_fun_mice <- function(df, target){
init <- mice(df, maxit=0, remove.collinear = FALSE, remove.constant = FALSE)
# Ensure the target variable is not imputed
init$predictorMatrix[, target] <- 0
imputed <- mice(df, method=init$method, predictorMatrix=init$predictorMatrix, m=5, nnet.MaxNWts = 5000, remove.collinear = FALSE, remove.constant = FALSE)
completed <- mice::complete(imputed)
return(completed)
}
imputed_train <- imputation_fun_mice(df_train, "NegOutcome")
imputed_test <- imputation_fun_mice(df_test, "NegOutcome")
# Count NAs each column to make sure imputation worked
colSums(is.na(imputed_train))
colSums(is.na(imputed_test))
View(imputed_test)
# Load in Libraries
library(NHANES)
library(dplyr)
library(haven)
library(tidyverse)
library(caret)
library(tidymodels)
library(tidyverse)
library(readr)
library(corrplot)
library(CVrisk)
# For Imputing
library(mice)
library(missForest)
library(VIM)
library(softImpute)
library(ggplot2)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Split data before imputing
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
df_11_12 <- read.csv("Cleaned Data/11_12_cleaned.csv")
df_11_12$Year <- c(1)
df_13_14 <- read.csv("Cleaned Data/13_14_cleaned.csv")
df_13_14$Year <- c(2)
df_15_16 <- read.csv("Cleaned Data/15_16_cleaned.csv")
df_15_16$Year <- c(3)
df_17_18 <- read.csv("Cleaned Data/17_18_cleaned.csv")
df_17_18$Year <- c(4)
# Combine all Data
full_df <- bind_rows(df_11_12, df_13_14, df_15_16, df_17_18)
full_df$X <- NULL
# Factoring the outcome/target variable
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
levels(full_df$NegOutcome) <- c("Non-Negative", "Negative")
# Count NAs each column
na_counts <- colSums(is.na(full_df))
print(na_counts)
# Barplot showing null values
# Convert to dataframe for plotting
na_data <- as.data.frame(na_counts)
na_data$Column <- rownames(na_data)
names(na_data) <- c("NA_Count", "Column")
ggplot(na_data, aes(x = reorder(Column, NA_Count), y = NA_Count)) +
geom_bar(stat = "identity", fill = "tomato") +
theme_minimal() +
labs(title = "Missing Values in Each Column", x = "Column", y = "Number of Missing Values") +
coord_flip() # Use coord_flip() to make the plot horizontal
## Plotting the target feature
ggplot(full_df, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Negative CVD Outcome", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table <- table(full_df$NegOutcome)
print(count_table)
# Calculate the percentage for each category
percentages <- prop.table(count_table) * 100
print(percentages)
# Splitting the Data
set.seed(1)
split <- initial_split(full_df, prop = 0.75, strata = "NegOutcome")
# 75%-25% split
df_train <- training(split)
df_test <- testing(split)
## Plotting the target feature
ggplot(df_train, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Training", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_train <- table(df_train$NegOutcome)
print(count_table_train)
# Calculate the percentage for each category
percentages_train <- prop.table(count_table_train) * 100
print(percentages_train)
## Plotting the target feature
ggplot(df_test, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Testing", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_test <- table(df_test$NegOutcome)
print(count_table_test)
# Calculate the percentage for each category
percentages_test <- prop.table(count_table_test) * 100
print(percentages_test)
# Impute Rest of Missing Data
imputation_fun_mice <- function(df, target){
init <- mice(df, maxit=0, remove.collinear = FALSE, remove.constant = FALSE)
# Ensure the target variable is not imputed
init$method[target] <- ""
init$predictorMatrix[, target] <- 0
imputed <- mice(df, method=init$method, predictorMatrix=init$predictorMatrix, m=5, nnet.MaxNWts = 5000, remove.collinear = FALSE, remove.constant = FALSE)
completed <- mice::complete(imputed)
return(completed)
}
imputed_train <- imputation_fun_mice(df_train, "NegOutcome")
imputed_test <- imputation_fun_mice(df_test, "NegOutcome")
# Count NAs each column to make sure imputation worked
colSums(is.na(imputed_train))
colSums(is.na(imputed_test))
View(imputed_train)
View(imputed_test)
# Applying the function to every row for specified columns
results_train <- apply(imputed_train[, c("Race1", "Sex", "Age", "TotalChol", "HDLChol", "AvgSysBP", "BPMed", "Smoking", "Diabetes")], 1, function(row) ascvd_10y_accaha(row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9]))
View(imputed_test)
View(imputed_train)
classtype(imputed_train$Smoking)
typeof(imputed_train$Smoking)
# Load in Libraries
library(NHANES)
library(dplyr)
library(haven)
library(tidyverse)
library(caret)
library(tidymodels)
library(tidyverse)
library(readr)
library(corrplot)
library(CVrisk)
# For Imputing
library(mice)
library(missForest)
library(VIM)
library(softImpute)
library(ggplot2)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Split data before imputing
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
df_11_12 <- read.csv("Cleaned Data/11_12_cleaned.csv")
df_11_12$Year <- c(1)
df_13_14 <- read.csv("Cleaned Data/13_14_cleaned.csv")
df_13_14$Year <- c(2)
df_15_16 <- read.csv("Cleaned Data/15_16_cleaned.csv")
df_15_16$Year <- c(3)
df_17_18 <- read.csv("Cleaned Data/17_18_cleaned.csv")
df_17_18$Year <- c(4)
# Combine all Data
full_df <- bind_rows(df_11_12, df_13_14, df_15_16, df_17_18)
full_df$X <- NULL
View(full_df)
full_df$HeartAttack <- NULL
full_df$Stroke <- NULL
# Factoring the outcome/target variable
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
levels(full_df$NegOutcome) <- c("Non-Negative", "Negative")
# Count NAs each column
na_counts <- colSums(is.na(full_df))
print(na_counts)
# Barplot showing null values
# Convert to dataframe for plotting
na_data <- as.data.frame(na_counts)
na_data$Column <- rownames(na_data)
names(na_data) <- c("NA_Count", "Column")
ggplot(na_data, aes(x = reorder(Column, NA_Count), y = NA_Count)) +
geom_bar(stat = "identity", fill = "tomato") +
theme_minimal() +
labs(title = "Missing Values in Each Column", x = "Column", y = "Number of Missing Values") +
coord_flip() # Use coord_flip() to make the plot horizontal
## Plotting the target feature
ggplot(full_df, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Negative CVD Outcome", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table <- table(full_df$NegOutcome)
print(count_table)
# Calculate the percentage for each category
percentages <- prop.table(count_table) * 100
print(percentages)
# Splitting the Data
set.seed(1)
split <- initial_split(full_df, prop = 0.75, strata = "NegOutcome")
# 75%-25% split
df_train <- training(split)
df_test <- testing(split)
## Plotting the target feature
ggplot(df_train, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Training", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_train <- table(df_train$NegOutcome)
print(count_table_train)
# Calculate the percentage for each category
percentages_train <- prop.table(count_table_train) * 100
print(percentages_train)
## Plotting the target feature
ggplot(df_test, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Testing", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_test <- table(df_test$NegOutcome)
print(count_table_test)
# Calculate the percentage for each category
percentages_test <- prop.table(count_table_test) * 100
print(percentages_test)
# Impute Rest of Missing Data
imputation_fun_mice <- function(df, target){
init <- mice(df, maxit=0, remove.collinear = FALSE, remove.constant = FALSE)
# Ensure the target variable is not imputed
init$method[target] <- ""
init$predictorMatrix[, target] <- 0
imputed <- mice(df, method=init$method, predictorMatrix=init$predictorMatrix, m=5, nnet.MaxNWts = 5000, remove.collinear = FALSE, remove.constant = FALSE)
completed <- mice::complete(imputed)
return(completed)
}
imputed_train <- imputation_fun_mice(df_train, "NegOutcome")
imputed_test <- imputation_fun_mice(df_test, "NegOutcome")
# Count NAs each column to make sure imputation worked
colSums(is.na(imputed_train))
colSums(is.na(imputed_test))
# Applying the function to every row for specified columns
results_train <- apply(imputed_train[, c("Race1", "Sex", "Age", "TotalChol", "HDLChol", "AvgSysBP", "BPMed", "Smoking", "Diabetes")], 1, function(row) ascvd_10y_accaha(row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9]))
help("ascvd_10y_accaha")
View(imputed_test)
browser(ascvd_10y_accaha())
print(ascvd_10y_accaha())
print(ascvd_10y_accaha
z
print(ascvd_10y_accaha)
column_types <- sapply(imputed_train, class)
print(column_types)
# Applying the function to every row for specified columns
results_train <- apply(imputed_train[, c("Race1", "Sex", "Age", "TotalChol", "HDLChol", "AvgSysBP", "BPMed", "Smoking", "Diabetes")], 1, function(row) ascvd_10y_accaha(row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[9]))
