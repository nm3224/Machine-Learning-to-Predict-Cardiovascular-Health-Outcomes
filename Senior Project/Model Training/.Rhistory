# PCE
sum(is.na(train_df))
sum(is.na(test_df))
View(train_df)
# Load in Data
train_df <- read.csv("Cleaned Data/imputed_train.csv")
test_df <- read.csv("Cleaned Data/imputed_test.csv")
# Re-code as binaries for ML
train_df$Race1 <- ifelse(train_df$Race1 %in% c("white", "other"), 0, 1)
train_df$Sex <- ifelse(train_df$Sex == "male", 0, 1)
train_df$X <- NULL
test_df$Race1 <- ifelse(test_df$Race1 %in% c("white", "other"), 0, 1)
test_df$Sex <- ifelse(test_df$Sex == "male", 0, 1)
test_df$X <- NULL
View(train_df)
View(test_df)
View(train_df)
View(train_df)
View(train_df)
# Removing NAs
train_df <- na.omit(train_df)
test_df <- na.omit(test_df)
# Changing to factors
train_df$Race2 <- factor(train_df$Race2)
test_df$Race2 <- factor(test_df$Race2)
train_df <- train_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
test_df <- test_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
blueprint <- recipe(NegOutcome ~ ., data = train_df) %>%
step_center(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP'))) %>%
step_scale(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP')))
## Estimating blueprint parameters
blueprint_prep <- prep(blueprint, training = train_df)
## Transforming data
transformed_train <- bake(blueprint_prep, new_data = train_df)
transformed_test <- bake(blueprint_prep, new_data = test_df)
View(transformed_train)
# Subset Appropriate Columns-- without SDOH, just PCE variables
train_df_PCE <- train_df[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
test_df_PCE <- test_df[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
# Subset Appropriate Columns-- with SDOH, and more stratified race variables
train_df_SDOH <- train_df[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
test_df_SDOH <- test_df[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
logr_model_PCE <- glm(NegOutcome ~., family=binomial, data=train_df_PCE)
summary(logr_model_PCE)
# Training set results
pred_train_PCE <- predict(logr_model_PCE, newdata = train_df_PCE, type="response")
# Change probabilities to 0, 1
pred_train_PCE <- ifelse(pred_train_PCE > 0.5, 1, 0)
# Test set results
pred_test_PCE <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
# Change probabilities to 0, 1
pred_test_PCE <- ifelse(pred_test_PCE > 0.5, 1, 0)
# Converting to factors
train_actual_PCE <- factor(train_df_PCE$NegOutcome, levels = c(0, 1))
test_actual_PCE <- factor(test_df_PCE$NegOutcome, levels = c(0, 1))
train_pred_PCE <- factor(pred_train_PCE, levels = c(0, 1))
test_pred_PCE <- factor(pred_test_PCE, levels = c(0, 1))
# Building Confusion Matrices
results_PCE_train <- confusionMatrix(train_actual_PCE, train_pred_PCE, positive = "1")
print(results_PCE_train)
results_PCE_test <- confusionMatrix(test_actual_PCE, test_pred_PCE, positive = "1")
print(results_PCE_test)
# create ROC object
roc_object <- roc(test_df_PCE$NegOutcome, pred_test_PCE)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
logr_model_SDOH <- glm(NegOutcome ~., family=binomial, data=train_df_SDOH)
summary(logr_model_SDOH)
# Training set results
pred_train_SDOH <- predict(logr_model_SDOH, newdata = train_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_train_SDOH <- ifelse(pred_train_SDOH > 0.5, 1, 0)
# Test set results
pred_test_SDOH <- predict(logr_model_SDOH, newdata = test_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_test_SDOH <- ifelse(pred_test_SDOH > 0.5, 1, 0)
# Converting to factors
train_actual_SDOH <- factor(train_df_SDOH$NegOutcome, levels = c(0, 1))
test_actual_SDOH <- factor(test_df_SDOH$NegOutcome, levels = c(0, 1))
train_pred_SDOH <- factor(pred_train_SDOH, levels = c(0, 1))
test_pred_SDOH <- factor(pred_test_SDOH, levels = c(0, 1))
# Building Confusion Matrices
results_SDOH_train <- confusionMatrix(train_actual_SDOH, train_pred_SDOH, positive = "1")
print(results_SDOH_train)
results_SDOH_test <- confusionMatrix(test_actual_SDOH, test_pred_SDOH, positive = "1")
print(results_SDOH_test)
# Training set results
pred_train_SDOH <- predict(logr_model_SDOH, newdata = train_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_train_SDOH <- ifelse(pred_train_SDOH > 0.5, 1, 0)
# Test set results
pred_test_SDOH <- predict(logr_model_SDOH, newdata = test_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_test_SDOH <- ifelse(pred_test_SDOH > 0.5, 1, 0)
# Converting to factors
train_actual_SDOH <- factor(train_df_SDOH$NegOutcome, levels = c(0, 1))
test_actual_SDOH <- factor(test_df_SDOH$NegOutcome, levels = c(0, 1))
train_pred_SDOH <- factor(pred_train_SDOH, levels = c(0, 1))
test_pred_SDOH <- factor(pred_test_SDOH, levels = c(0, 1))
# Building Confusion Matrices
results_SDOH_train <- confusionMatrix(train_actual_SDOH, train_pred_SDOH, positive = "1")
print(results_SDOH_train)
results_SDOH_test <- confusionMatrix(test_actual_SDOH, test_pred_SDOH, positive = "1")
print(results_SDOH_test)
# create ROC object
roc_object <- roc(test_df_SDOH$NegOutcome, pred_test_SDOH)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
# Subset Appropriate Columns-- without SDOH, just PCE variables
train_df_PCE <- transformed_train[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
test_df_PCE <- transformed_test[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
# Subset Appropriate Columns-- with SDOH, and more stratified race variables
train_df_SDOH <- transformed_train[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
test_df_SDOH <- transformed_test[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
logr_model_PCE <- glm(NegOutcome ~., family=binomial, data=train_df_PCE)
summary(logr_model_PCE)
# Training set results
pred_train_PCE <- predict(logr_model_PCE, newdata = train_df_PCE, type="response")
# Change probabilities to 0, 1
pred_train_PCE <- ifelse(pred_train_PCE > 0.5, 1, 0)
# Test set results
pred_test_PCE <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
# Change probabilities to 0, 1
pred_test_PCE <- ifelse(pred_test_PCE > 0.5, 1, 0)
# Converting to factors
train_actual_PCE <- factor(train_df_PCE$NegOutcome, levels = c(0, 1))
test_actual_PCE <- factor(test_df_PCE$NegOutcome, levels = c(0, 1))
train_pred_PCE <- factor(pred_train_PCE, levels = c(0, 1))
test_pred_PCE <- factor(pred_test_PCE, levels = c(0, 1))
# Building Confusion Matrices
results_PCE_train <- confusionMatrix(train_actual_PCE, train_pred_PCE, positive = "1")
print(results_PCE_train)
results_PCE_test <- confusionMatrix(test_actual_PCE, test_pred_PCE, positive = "1")
print(results_PCE_test)
# create ROC object
roc_object <- roc(test_df_PCE$NegOutcome, pred_test_PCE)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
logr_model_SDOH <- glm(NegOutcome ~., family=binomial, data=train_df_SDOH)
summary(logr_model_SDOH)
# Training set results
pred_train_SDOH <- predict(logr_model_SDOH, newdata = train_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_train_SDOH <- ifelse(pred_train_SDOH > 0.5, 1, 0)
# Test set results
pred_test_SDOH <- predict(logr_model_SDOH, newdata = test_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_test_SDOH <- ifelse(pred_test_SDOH > 0.5, 1, 0)
# Converting to factors
train_actual_SDOH <- factor(train_df_SDOH$NegOutcome, levels = c(0, 1))
test_actual_SDOH <- factor(test_df_SDOH$NegOutcome, levels = c(0, 1))
train_pred_SDOH <- factor(pred_train_SDOH, levels = c(0, 1))
test_pred_SDOH <- factor(pred_test_SDOH, levels = c(0, 1))
# Building Confusion Matrices
results_SDOH_train <- confusionMatrix(train_actual_SDOH, train_pred_SDOH, positive = "1")
print(results_SDOH_train)
results_SDOH_test <- confusionMatrix(test_actual_SDOH, test_pred_SDOH, positive = "1")
print(results_SDOH_test)
# create ROC object
roc_object <- roc(test_df_SDOH$NegOutcome, pred_test_SDOH)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
View(test_df_PCE)
View(train_df_PCE)
View(test_df_SDOH)
df_pred <- data.frame(x1 = seq(min(train_df_PCE$NegOutcome), max(train_df_PCE$NegOutcome), length.out = 100))
df_pred$probability <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
View(df_pred)
df_pred <- data.frame(NegOutcome = seq(min(train_df_PCE$NegOutcome), max(train_df_PCE$NegOutcome), length.out = 100))
df_pred$probability <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
View(train_df)
# Load in Libraries
library(NHANES)
library(dplyr)
library(haven)
library(tidyverse)
library(caret)
library(tidymodels)
library(tidyverse)
library(readr)
library(corrplot)
library(CVrisk)
# For Imputing
library(mice)
library(missForest)
library(VIM)
library(softImpute)
library(ggplot2)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
# Load in Data
df_11_12 <- read.csv("Cleaned Data/11_12_cleaned.csv")
df_11_12$Year <- c(1)
df_13_14 <- read.csv("Cleaned Data/13_14_cleaned.csv")
df_13_14$Year <- c(2)
df_15_16 <- read.csv("Cleaned Data/15_16_cleaned.csv")
df_15_16$Year <- c(3)
df_17_18 <- read.csv("Cleaned Data/17_18_cleaned.csv")
df_17_18$Year <- c(4)
# Combine all Data
full_df <- bind_rows(df_11_12, df_13_14, df_15_16, df_17_18)
full_df$X <- NULL
full_df$HeartAttack <- NULL
full_df$Stroke <- NULL
full_df$CoronaryDisease <- NULL
full_df$HeartFailure <- NULL
# Factoring the outcome/target variable
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
# Count NAs each column
na_counts <- colSums(is.na(full_df))
print(na_counts)
# Barplot showing null values
# Convert to dataframe for plotting
na_data <- as.data.frame(na_counts)
na_data$Column <- rownames(na_data)
names(na_data) <- c("NA_Count", "Column")
ggplot(na_data, aes(x = reorder(Column, NA_Count), y = NA_Count)) +
geom_bar(stat = "identity", fill = "tomato") +
theme_minimal() +
labs(title = "Missing Values in Each Column", x = "Column", y = "Number of Missing Values") +
coord_flip() # Use coord_flip() to make the plot horizontal
## Plotting the target feature
ggplot(full_df, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Negative CVD Outcome", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table <- table(full_df$NegOutcome)
print(count_table)
# Calculate the percentage for each category
percentages <- prop.table(count_table) * 100
print(percentages)
# Checking for near zero variances
nearZeroVar(full_df, saveMetrics = TRUE)   # all metrics
# Splitting the Data
set.seed(1)
split <- initial_split(full_df, prop = 0.75, strata = "NegOutcome")
# 75%-25% split
df_train <- training(split)
df_test <- testing(split)
## Plotting the target feature
ggplot(df_train, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Training", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_train <- table(df_train$NegOutcome)
print(count_table_train)
# Calculate the percentage for each category
percentages_train <- prop.table(count_table_train) * 100
print(percentages_train)
## Plotting the target feature
ggplot(df_test, aes(x = NegOutcome)) +
geom_bar(fill = "steelblue", color = "black") +
labs(title = "Distribution of Target Feature: Testing", x = "Negative CVD Outcome", y = "Count") +
theme_minimal()
# Count of each: approvals vs. denials
count_table_test <- table(df_test$NegOutcome)
print(count_table_test)
# Calculate the percentage for each category
percentages_test <- prop.table(count_table_test) * 100
print(percentages_test)
# Impute Rest of Missing Data
imputation_fun_mice <- function(df, target){
init <- mice(df, maxit=0, remove.collinear = FALSE, remove.constant = FALSE)
# Ensure the target variable is not imputed
init$method[target] <- ""
init$predictorMatrix[, target] <- 0
imputed <- mice(df, method=init$method, predictorMatrix=init$predictorMatrix, m=5, nnet.MaxNWts = 5000, remove.collinear = FALSE, remove.constant = FALSE)
completed <- mice::complete(imputed)
return(completed)
}
imputed_train <- imputation_fun_mice(df_train, "NegOutcome")
imputed_test <- imputation_fun_mice(df_test, "NegOutcome")
# Count NAs each column to make sure imputation worked
colSums(is.na(imputed_train))
colSums(is.na(imputed_test))
column_types <- sapply(imputed_train, class)
print(column_types)
# Applying the function to every row for specified columns
results_train <- apply(imputed_train[, c("Race1", "Sex", "Age", "TotalChol", "HDLChol", "AvgSysBP", "BPMed", "Smoking", "Diabetes")], 1, function(row) ascvd_10y_accaha(row[1], row[2], as.numeric(row[3]), as.numeric(row[4]), as.numeric(row[5]), as.numeric(row[6]), as.numeric(row[7]), as.numeric(row[8]), as.numeric(row[9])))
View(df_train)
results_test <- apply(imputed_test[, c("Race1", "Sex", "Age", "TotalChol", "HDLChol", "AvgSysBP", "BPMed", "Smoking", "Diabetes")], 1, function(row) ascvd_10y_accaha(row[1], row[2], as.numeric(row[3]), as.numeric(row[4]), as.numeric(row[5]), as.numeric(row[6]), as.numeric(row[7]), as.numeric(row[8]), as.numeric(row[9])))
# Note that ASCVD risk score can only be calculated for individuals between age range 20-79
# Adding the result as a new column to the DataFrames
imputed_train$ASCVD <- results_train
imputed_test$ASCVD <- results_test
# Combine dataframes
full_df_cleaned <- rbind(imputed_train, imputed_test)
# Saving CSVs
write.csv(imputed_train, "Cleaned Data/imputed_train.csv")
write.csv(imputed_test, "Cleaned Data/imputed_test.csv")
write.csv(full_df_cleaned, "Cleaned Data/imputed_full.csv")
# Load in Data
train_df <- read.csv("Cleaned Data/imputed_train.csv")
test_df <- read.csv("Cleaned Data/imputed_test.csv")
full_df <- read.csv("Cleaned Data/imputed_full.csv")
# Re-code as binaries for ML
train_df$Race1 <- ifelse(train_df$Race1 %in% c("white", "other"), 0, 1)
train_df$Sex <- ifelse(train_df$Sex == "male", 0, 1)
train_df$X <- NULL
test_df$Race1 <- ifelse(test_df$Race1 %in% c("white", "other"), 0, 1)
test_df$Sex <- ifelse(test_df$Sex == "male", 0, 1)
test_df$X <- NULL
full_df$Race1 <- ifelse(full_df$Race1 %in% c("white", "other"), 0, 1)
full_df$Sex <- ifelse(full_df$Sex == "male", 0, 1)
full_df$X <- NULL
# Load in Libraries
library(CVrisk)
library(ggplot2)
library(dplyr)
library(haven)
library(tidyverse)
library(broom)
library(ggplot2)
library(caret)
library(tidymodels)
library(pROC)
# For Training
library(OpenML)
library(DT)
library(randomForest)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
View(full_df)
# Compare ASCVD score between within sex and Food Security categories
full_df %>%
group_by(Sex, FoodSecurity) %>%
summarize(n = n(),
mean = mean(ASCVD, na.rm = T),
sd   = sd(ASCVD, na.rm = T)) %>%
ggplot(aes(x = Sex, y = mean, fill = FoodSecurity)) +
geom_bar(stat = "identity", position = "dodge") +
geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd),
width = 0.5, size = 0.75, position = position_dodge(0.9)) +
geom_text(aes(y = 5, label = n), position = position_dodge(0.9)) +
labs(y = "ASCVD Score", fill = "FoodSecurity", x = "Sex")
# Compare ASCVD score between within sex and Food Security categories
full_df %>%
filter(!is.na(Sex) & !is.na(FoodSecurity)) %>%
group_by(Sex, FoodSecurity) %>%
summarize(n = n(),
mean = mean(ASCVD, na.rm = T),
sd   = sd(ASCVD, na.rm = T)) %>%
ggplot(aes(x = Sex, y = mean, fill = FoodSecurity)) +
geom_bar(stat = "identity", position = "dodge") +
geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd),
width = 0.5, size = 0.75, position = position_dodge(0.9)) +
geom_text(aes(y = 5, label = n), position = position_dodge(0.9)) +
labs(y = "ASCVD Score", fill = "FoodSecurity", x = "Sex")
# Compare Negative Outcomes by Food Security categories
barplot(table(full_df$NegOutcome, full_df$FoodSecurity),
beside = T,
legend.text = T,
xlab = "Food Security",
ylab = "Frequency",
main = "Negative CVD Outcome by Food Security Category"
# Add a box around the plot
box()
# Compare Negative Outcomes by Food Security categories
barplot(table(full_df$NegOutcome, full_df$FoodSecurity),
beside = T,
legend.text = T,
xlab = "Food Security",
ylab = "Frequency",
main = "Negative CVD Outcome by Food Security Category")
# Add a box around the plot
box()
View(train_df)
View(full_df)
# Compare Negative Outcomes by FastFood categories
barplot(table(full_df$NegOutcome, full_df$FastFood),
beside = T,
legend.text = T,
xlab = "Fast Food",
ylab = "Frequency",
main = "Negative CVD Outcome by Fast Food")
# Add a box around the plot
box()
View(full_df)
View(train_df)
# Load in Libraries
library(CVrisk)
library(ggplot2)
library(dplyr)
library(haven)
library(tidyverse)
library(broom)
library(ggplot2)
library(caret)
library(tidymodels)
library(pROC)
# For Training
library(OpenML)
library(DT)
library(randomForest)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
train_df <- read.csv("Cleaned Data/imputed_train.csv")
test_df <- read.csv("Cleaned Data/imputed_test.csv")
full_df <- read.csv("Cleaned Data/imputed_full.csv")
# Re-code as binaries for ML
train_df$Race1 <- ifelse(train_df$Race1 %in% c("white", "other"), 0, 1)
train_df$Sex <- ifelse(train_df$Sex == "male", 0, 1)
train_df$X <- NULL
test_df$Race1 <- ifelse(test_df$Race1 %in% c("white", "other"), 0, 1)
test_df$Sex <- ifelse(test_df$Sex == "male", 0, 1)
test_df$X <- NULL
full_df$Race1 <- ifelse(full_df$Race1 %in% c("white", "other"), 0, 1)
full_df$Sex <- ifelse(full_df$Sex == "male", 0, 1)
full_df$X <- NULL
# Compare Negative Outcomes by FastFood categories
barplot(table(full_df$NegOutcome, full_df$FastFood),
beside = T,
legend.text = T,
xlab = "Fast Food",
ylab = "Frequency",
main = "Negative CVD Outcome by Fast Food")
# Add a box around the plot
box()
# PCE
sum(is.na(train_df))
sum(is.na(test_df))
# Removing NAs
train_df <- na.omit(train_df)
test_df <- na.omit(test_df)
# Changing to factors
train_df$Race2 <- factor(train_df$Race2)
test_df$Race2 <- factor(test_df$Race2)
train_df <- train_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
test_df <- test_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
blueprint <- recipe(NegOutcome ~ ., data = train_df) %>%
step_center(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP'))) %>%
step_scale(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP')))
## Estimating blueprint parameters
blueprint_prep <- prep(blueprint, training = train_df)
## Transforming data
transformed_train <- bake(blueprint_prep, new_data = train_df)
transformed_test <- bake(blueprint_prep, new_data = test_df)
# Subset Appropriate Columns-- without SDOH, just PCE variables
train_df_PCE <- transformed_train[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
test_df_PCE <- transformed_test[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
# Subset Appropriate Columns-- with SDOH, and more stratified race variables
train_df_SDOH <- transformed_train[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
test_df_SDOH <- transformed_test[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
logr_model_PCE <- glm(NegOutcome ~., family=binomial, data=train_df_PCE)
summary(logr_model_PCE)
# Training set results
pred_train_PCE <- predict(logr_model_PCE, newdata = train_df_PCE, type="response")
# Change probabilities to 0, 1
pred_train_PCE <- ifelse(pred_train_PCE > 0.5, 1, 0)
# Test set results
pred_test_PCE <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
# Change probabilities to 0, 1
pred_test_PCE <- ifelse(pred_test_PCE > 0.5, 1, 0)
# Converting to factors
train_actual_PCE <- factor(train_df_PCE$NegOutcome, levels = c(0, 1))
test_actual_PCE <- factor(test_df_PCE$NegOutcome, levels = c(0, 1))
train_pred_PCE <- factor(pred_train_PCE, levels = c(0, 1))
test_pred_PCE <- factor(pred_test_PCE, levels = c(0, 1))
# Building Confusion Matrices
results_PCE_train <- confusionMatrix(train_actual_PCE, train_pred_PCE, positive = "1")
print(results_PCE_train)
results_PCE_test <- confusionMatrix(test_actual_PCE, test_pred_PCE, positive = "1")
print(results_PCE_test)
# create ROC object
roc_object <- roc(test_df_PCE$NegOutcome, pred_test_PCE)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
logr_model_SDOH <- glm(NegOutcome ~., family=binomial, data=train_df_SDOH)
summary(logr_model_SDOH)
# Training set results
pred_train_SDOH <- predict(logr_model_SDOH, newdata = train_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_train_SDOH <- ifelse(pred_train_SDOH > 0.5, 1, 0)
# Test set results
pred_test_SDOH <- predict(logr_model_SDOH, newdata = test_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_test_SDOH <- ifelse(pred_test_SDOH > 0.5, 1, 0)
# Converting to factors
train_actual_SDOH <- factor(train_df_SDOH$NegOutcome, levels = c(0, 1))
test_actual_SDOH <- factor(test_df_SDOH$NegOutcome, levels = c(0, 1))
train_pred_SDOH <- factor(pred_train_SDOH, levels = c(0, 1))
test_pred_SDOH <- factor(pred_test_SDOH, levels = c(0, 1))
# Building Confusion Matrices
results_SDOH_train <- confusionMatrix(train_actual_SDOH, train_pred_SDOH, positive = "1")
print(results_SDOH_train)
results_SDOH_test <- confusionMatrix(test_actual_SDOH, test_pred_SDOH, positive = "1")
print(results_SDOH_test)
View(train_df_PCE)
View(train_df_SDOH)
# create ROC object
roc_object <- roc(test_df_SDOH$NegOutcome, pred_test_SDOH)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
View(test_df_SDOH)
