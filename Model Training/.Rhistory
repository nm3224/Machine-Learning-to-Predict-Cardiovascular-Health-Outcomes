library(DT)
library(randomForest)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
View(full_df)
# Compare ASCVD score between within sex and Food Security categories
full_df %>%
group_by(Sex, FoodSecurity) %>%
summarize(n = n(),
mean = mean(ASCVD, na.rm = T),
sd   = sd(ASCVD, na.rm = T)) %>%
ggplot(aes(x = Sex, y = mean, fill = FoodSecurity)) +
geom_bar(stat = "identity", position = "dodge") +
geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd),
width = 0.5, size = 0.75, position = position_dodge(0.9)) +
geom_text(aes(y = 5, label = n), position = position_dodge(0.9)) +
labs(y = "ASCVD Score", fill = "FoodSecurity", x = "Sex")
# Compare ASCVD score between within sex and Food Security categories
full_df %>%
filter(!is.na(Sex) & !is.na(FoodSecurity)) %>%
group_by(Sex, FoodSecurity) %>%
summarize(n = n(),
mean = mean(ASCVD, na.rm = T),
sd   = sd(ASCVD, na.rm = T)) %>%
ggplot(aes(x = Sex, y = mean, fill = FoodSecurity)) +
geom_bar(stat = "identity", position = "dodge") +
geom_errorbar(aes(ymin = mean - sd, ymax = mean + sd),
width = 0.5, size = 0.75, position = position_dodge(0.9)) +
geom_text(aes(y = 5, label = n), position = position_dodge(0.9)) +
labs(y = "ASCVD Score", fill = "FoodSecurity", x = "Sex")
# Compare Negative Outcomes by Food Security categories
barplot(table(full_df$NegOutcome, full_df$FoodSecurity),
beside = T,
legend.text = T,
xlab = "Food Security",
ylab = "Frequency",
main = "Negative CVD Outcome by Food Security Category"
# Add a box around the plot
box()
# Compare Negative Outcomes by Food Security categories
barplot(table(full_df$NegOutcome, full_df$FoodSecurity),
beside = T,
legend.text = T,
xlab = "Food Security",
ylab = "Frequency",
main = "Negative CVD Outcome by Food Security Category")
# Add a box around the plot
box()
View(train_df)
View(full_df)
# Compare Negative Outcomes by FastFood categories
barplot(table(full_df$NegOutcome, full_df$FastFood),
beside = T,
legend.text = T,
xlab = "Fast Food",
ylab = "Frequency",
main = "Negative CVD Outcome by Fast Food")
# Add a box around the plot
box()
View(full_df)
View(train_df)
# Load in Libraries
library(CVrisk)
library(ggplot2)
library(dplyr)
library(haven)
library(tidyverse)
library(broom)
library(ggplot2)
library(caret)
library(tidymodels)
library(pROC)
# For Training
library(OpenML)
library(DT)
library(randomForest)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
## Visualizations for logistic regression and then different model (important variables, summary statistics, scores)
# Load in Data
train_df <- read.csv("Cleaned Data/imputed_train.csv")
test_df <- read.csv("Cleaned Data/imputed_test.csv")
full_df <- read.csv("Cleaned Data/imputed_full.csv")
# Re-code as binaries for ML
train_df$Race1 <- ifelse(train_df$Race1 %in% c("white", "other"), 0, 1)
train_df$Sex <- ifelse(train_df$Sex == "male", 0, 1)
train_df$X <- NULL
test_df$Race1 <- ifelse(test_df$Race1 %in% c("white", "other"), 0, 1)
test_df$Sex <- ifelse(test_df$Sex == "male", 0, 1)
test_df$X <- NULL
full_df$Race1 <- ifelse(full_df$Race1 %in% c("white", "other"), 0, 1)
full_df$Sex <- ifelse(full_df$Sex == "male", 0, 1)
full_df$X <- NULL
# Compare Negative Outcomes by FastFood categories
barplot(table(full_df$NegOutcome, full_df$FastFood),
beside = T,
legend.text = T,
xlab = "Fast Food",
ylab = "Frequency",
main = "Negative CVD Outcome by Fast Food")
# Add a box around the plot
box()
# PCE
sum(is.na(train_df))
sum(is.na(test_df))
# Removing NAs
train_df <- na.omit(train_df)
test_df <- na.omit(test_df)
# Changing to factors
train_df$Race2 <- factor(train_df$Race2)
test_df$Race2 <- factor(test_df$Race2)
train_df <- train_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
test_df <- test_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
blueprint <- recipe(NegOutcome ~ ., data = train_df) %>%
step_center(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP'))) %>%
step_scale(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP')))
## Estimating blueprint parameters
blueprint_prep <- prep(blueprint, training = train_df)
## Transforming data
transformed_train <- bake(blueprint_prep, new_data = train_df)
transformed_test <- bake(blueprint_prep, new_data = test_df)
# Subset Appropriate Columns-- without SDOH, just PCE variables
train_df_PCE <- transformed_train[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
test_df_PCE <- transformed_test[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
# Subset Appropriate Columns-- with SDOH, and more stratified race variables
train_df_SDOH <- transformed_train[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
test_df_SDOH <- transformed_test[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
logr_model_PCE <- glm(NegOutcome ~., family=binomial, data=train_df_PCE)
summary(logr_model_PCE)
# Training set results
pred_train_PCE <- predict(logr_model_PCE, newdata = train_df_PCE, type="response")
# Change probabilities to 0, 1
pred_train_PCE <- ifelse(pred_train_PCE > 0.5, 1, 0)
# Test set results
pred_test_PCE <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
# Change probabilities to 0, 1
pred_test_PCE <- ifelse(pred_test_PCE > 0.5, 1, 0)
# Converting to factors
train_actual_PCE <- factor(train_df_PCE$NegOutcome, levels = c(0, 1))
test_actual_PCE <- factor(test_df_PCE$NegOutcome, levels = c(0, 1))
train_pred_PCE <- factor(pred_train_PCE, levels = c(0, 1))
test_pred_PCE <- factor(pred_test_PCE, levels = c(0, 1))
# Building Confusion Matrices
results_PCE_train <- confusionMatrix(train_actual_PCE, train_pred_PCE, positive = "1")
print(results_PCE_train)
results_PCE_test <- confusionMatrix(test_actual_PCE, test_pred_PCE, positive = "1")
print(results_PCE_test)
# create ROC object
roc_object <- roc(test_df_PCE$NegOutcome, pred_test_PCE)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
logr_model_SDOH <- glm(NegOutcome ~., family=binomial, data=train_df_SDOH)
summary(logr_model_SDOH)
# Training set results
pred_train_SDOH <- predict(logr_model_SDOH, newdata = train_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_train_SDOH <- ifelse(pred_train_SDOH > 0.5, 1, 0)
# Test set results
pred_test_SDOH <- predict(logr_model_SDOH, newdata = test_df_SDOH, type="response")
# Change probabilities to 0, 1
pred_test_SDOH <- ifelse(pred_test_SDOH > 0.5, 1, 0)
# Converting to factors
train_actual_SDOH <- factor(train_df_SDOH$NegOutcome, levels = c(0, 1))
test_actual_SDOH <- factor(test_df_SDOH$NegOutcome, levels = c(0, 1))
train_pred_SDOH <- factor(pred_train_SDOH, levels = c(0, 1))
test_pred_SDOH <- factor(pred_test_SDOH, levels = c(0, 1))
# Building Confusion Matrices
results_SDOH_train <- confusionMatrix(train_actual_SDOH, train_pred_SDOH, positive = "1")
print(results_SDOH_train)
results_SDOH_test <- confusionMatrix(test_actual_SDOH, test_pred_SDOH, positive = "1")
print(results_SDOH_test)
View(train_df_PCE)
View(train_df_SDOH)
# create ROC object
roc_object <- roc(test_df_SDOH$NegOutcome, pred_test_SDOH)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc(roc_object), 2)), col = "#1c61b6")
View(test_df_SDOH)
# Load in Libraries
library(CVrisk)
library(ggplot2)
library(dplyr)
library(haven)
library(tidyverse)
library(broom)
library(ggplot2)
library(caret)
library(tidymodels)
library(pROC)
library(tableone)
library(knitr)
library(crosstable)
library(flextable)
library(broom)
# For Training
library(OpenML)
library(randomForest)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Senior Project')
# Load in Data
train_df <- read.csv("Cleaned Data/imputed_train.csv")
# Load in Libraries
library(CVrisk)
library(ggplot2)
library(dplyr)
library(haven)
library(tidyverse)
library(broom)
library(ggplot2)
library(caret)
library(tidymodels)
library(pROC)
library(tableone)
library(knitr)
library(crosstable)
library(flextable)
library(broom)
# For Training
library(OpenML)
library(randomForest)
knitr::opts_knit$set(root.dir = '/Users/noreenmayat/Desktop/Github/Machine-Learning-to-Predict-Cardiovascular-Outcomes')
# Load in Data
train_df <- read.csv("Cleaned Data/imputed_train.csv")
test_df <- read.csv("Cleaned Data/imputed_test.csv")
full_df <- read.csv("Cleaned Data/imputed_full.csv")
# Re-code as binaries for ML
train_df$Race1 <- ifelse(train_df$Race1 %in% c("white", "other"), 0, 1)
train_df$Sex <- ifelse(train_df$Sex == "male", 0, 1)
train_df$X <- NULL
test_df$Race1 <- ifelse(test_df$Race1 %in% c("white", "other"), 0, 1)
test_df$Sex <- ifelse(test_df$Sex == "male", 0, 1)
test_df$X <- NULL
full_df$Race1 <- ifelse(full_df$Race1 %in% c("white", "other"), 0, 1)
full_df$Sex <- ifelse(full_df$Sex == "male", 0, 1)
full_df$X <- NULL
# Converting to factors for visuals
full_df$NegOutcome <- factor(full_df$NegOutcome, levels = c(0, 1))
levels(full_df$NegOutcome) <- c("No", "Yes")
binary_vars <- c("Sex", "Race1", "BPMed", "Diabetes", "Smoking")
# Convert binary variables to factors with appropriate levels and labels
full_df[binary_vars] <- lapply(full_df[binary_vars], function(x) factor(x, levels = c(0, 1), labels = c("No", "Yes")))
full_df$Ann_HHIncome <- factor(full_df$Ann_HHIncome)
levels(full_df$Ann_HHIncome) <- c("Lower: [$0-$50,000)", "Middle: [$50,00-$100,000)", "Upper: $100,000>")
# Convert 'race' into a factor
full_df$Race2 <- factor(full_df$Race2)
levels(full_df$Race2) <- c("Mexican American", "Other Hispanic", "Non-Hispanic White", "Non-Hispanic Black", "Non-Hispanic Asian", "Other Race")
# Food Security
full_df$FoodSecurity <- factor(full_df$FoodSecurity)
levels(full_df$FoodSecurity) <- c("Full Food Security", "Marginal Food Security", "Low Food Security", "Very Low Food Security")
# Balanced Meals
full_df$BalancedMeals <- factor(full_df$BalancedMeals)
levels(full_df$BalancedMeals) <- c("Could Afford", "Could Sometimes Afford", "Couldn't Afford")
# Low Cost Meals
full_df$LowCost <- factor(full_df$LowCost)
levels(full_df$LowCost) <- c("Didn't buy LC", "Sometimes bought LC", "Usually bought LC")
# Violin plot for ASCVD score by outcome
ggplot(full_df, aes(x=NegOutcome, y=ASCVD, fill=NegOutcome)) +
geom_violin(trim=FALSE) +
labs(title="Distribution of ASCVD Score by CVD Events", x="CVD Event", y="ASCVD Score", fill = 'CVD Event') +
ylim(0, 100) +
scale_fill_brewer(palette="Accent")
average_scores <- full_df %>%
group_by(Race2) %>%
summarise(average_score = mean(ASCVD, na.rm = TRUE), sem = sd(ASCVD, na.rm = TRUE) / sqrt(n())) %>%
ungroup()
ggplot(average_scores, aes(x = Race2, y = average_score, fill = Race2)) +
geom_bar(stat = "identity", position = position_dodge()) +
geom_errorbar(aes(ymin = average_score - sem, ymax = average_score + sem),
width = 0.2,                   # Controls the width of the error bars
position = position_dodge(0.9)) +
scale_fill_brewer(palette = "Accent") +
theme_minimal() +
labs(x = "Race", y = "Average ASCVD Score", title = "Average ASCVD Scores by Race (Stratified)", fill = "Race") +
geom_text(aes(label = round(average_score, 2)), vjust = -1, size = 3.5) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
average_scores <- full_df %>%
group_by(Ann_HHIncome) %>%
summarise(average_score = mean(ASCVD, na.rm = TRUE), sem = sd(ASCVD, na.rm = TRUE) / sqrt(n())) %>%
ungroup()
ggplot(average_scores, aes(x = Ann_HHIncome, y = average_score, fill = Ann_HHIncome)) +
geom_bar(stat = "identity", position = position_dodge()) +
geom_errorbar(aes(ymin = average_score - sem, ymax = average_score + sem),
width = 0.2,                   # Controls the width of the error bars
position = position_dodge(0.9)) +
scale_fill_brewer(palette = "Accent") +
theme_minimal() +
labs(x = "Income Category", y = "Average ASCVD Score", title = "Average ASCVD Scores by Income Categories", fill = "Income Category") +
geom_text(aes(label = round(average_score, 2)), vjust = -1.1, size = 3.5)
# table 1 - avg value and std for each covariant; split between negative vs. non-negative outcomes in 2 columns, each row is a different covariant -- R table 1 package
covariates <- c("Age", "HDLChol", "TotalChol", "AvgSysBP", "PovertyRatio", "FastFood", "ASCVD")
catVars <- c("Sex", "Race1", "Race2", "BPMed", "Diabetes", "Smoking", "Ann_HHIncome", "BalancedMeals", "LowCost", "FoodSecurity")
# Combine lists
vars <- c(covariates, catVars)
# Create a table one object
table1 <- CreateTableOne(vars = vars, strata = "NegOutcome", data = full_df, factorVars = catVars,
test = FALSE)
# Print the table with mean and SD for continuous variables
print(table1, nonnormal = covariates, showAllLevels = TRUE)
# Aesthetics
cross_table <- crosstable(full_df, cols=any_of(vars),
by=NegOutcome, showNA = "no") %>%
as_flextable()
autofit(cross_table)
# Convert your data to long format with tidyr's pivot_longer
long_df <- pivot_longer(full_df,
cols = covariates,
names_to = "variable",
values_to = "value")
clean_df <- long_df %>%
filter(!is.na(NegOutcome), !is.na(value))
# Now, create individual boxplots for each variable
ggplot(clean_df, aes(x = NegOutcome, y = value, fill = NegOutcome)) +
geom_boxplot(na.rm = TRUE) +
facet_wrap(~variable, scales = "free_y") + # Each variable on its own y scale
theme(axis.text.x = element_text(angle = 90, hjust = 1)) + # Rotate x-axis labels for clarity
labs(x = "Outcome", y = "Value", fill = "CVD Event") # Label the axes and legend
# PCE
sum(is.na(train_df))
sum(is.na(test_df))
# Removing NAs
train_df <- na.omit(train_df)
test_df <- na.omit(test_df)
# Changing to factors
train_df$Race2 <- factor(train_df$Race2)
test_df$Race2 <- factor(test_df$Race2)
train_df <- train_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
test_df <- test_df %>%
mutate(across(all_of(c('Ann_FamIncome', 'Ann_HHIncome', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity')), ~factor(.x, levels = as.character(0:max(.x, na.rm = TRUE)), ordered = TRUE)))
blueprint <- recipe(NegOutcome ~ ., data = train_df) %>%
step_center(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP'))) %>%
step_scale(all_of(c('Age', 'PovertyRatio', 'HDLChol', 'TotalChol', 'AvgSysBP')))
## Estimating blueprint parameters
blueprint_prep <- prep(blueprint, training = train_df)
## Transforming data
transformed_train <- bake(blueprint_prep, new_data = train_df)
transformed_test <- bake(blueprint_prep, new_data = test_df)
# Subset Appropriate Columns-- without SDOH, just PCE variables
train_df_PCE <- transformed_train[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
test_df_PCE <- transformed_test[c('Age', 'Sex', 'Race1', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'NegOutcome')]
# Subset Appropriate Columns-- with SDOH, and more stratified race variables
train_df_SDOH <- transformed_train[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
test_df_SDOH <- transformed_test[c('Age', 'Sex', 'Race2', 'HDLChol', 'TotalChol', 'AvgSysBP', 'BPMed', 'Diabetes', 'Smoking', 'Ann_FamIncome', 'Ann_HHIncome', 'PovertyRatio', 'FastFood', 'BalancedMeals', 'LowCost', 'FoodSecurity', 'NegOutcome')]
# Converting to factors
train_df_PCE$NegOutcome <- factor(train_df_PCE$NegOutcome, levels = c(0, 1))
test_df_PCE$NegOutcome <- factor(test_df_PCE$NegOutcome, levels = c(0, 1))
train_df_SDOH$NegOutcome <- factor(train_df_SDOH$NegOutcome, levels = c(0, 1))
test_df_SDOH$NegOutcome <- factor(test_df_SDOH$NegOutcome, levels = c(0, 1))
logr_model_PCE <- glm(NegOutcome ~., family=binomial, data=train_df_PCE)
summary(logr_model_PCE)
tidy_model <- tidy(logr_model_PCE)
ft <- flextable(tidy_model)
format_pvalue <- function(p) {
sapply(p, function(x) {
if (x < 2e-16) {
# Represent extremely small p-values as "< 2e-16"
ifelse(x < 0.05, "< 2e-16*", "< 2e-16")
} else if (x < 0.001) {
# Use scientific notation with exactly two digits in the exponent for small but not extreme values
ifelse(x < 0.05, sprintf("%.2e*", x), sprintf("%.2e", x))
} else {
# Display up to six decimal places, but no unnecessary trailing zeros for larger values
formatted_value <- strip_trailing_zeros(sprintf("%.6f", x))
ifelse(x < 0.05, paste0(formatted_value, "*"), formatted_value)
}
})
}
# Helper function to strip unnecessary trailing zeros
strip_trailing_zeros <- function(num_str) {
sub("0+$", "", sub("\\.$", "", num_str))
}
# Apply custom formatting to different columns
ft <- set_formatter(ft,
estimate = function(x) format(x, digits = 4, nsmall = 4),    # 4 decimal places
std.error = function(x) format(x, digits = 4, nsmall = 4),
statistic = function(x) format(x, digits = 3, nsmall = 3),
p.value = format_pvalue,     # 4 decimal places for p-values
conf.low = function(x) format(x, digits = 4, nsmall = 4),
conf.high = function(x) format(x, digits = 4, nsmall = 4)
)
print(ft)
# Training set results
pred_train_PCE <- predict(logr_model_PCE, newdata = train_df_PCE, type="response")
# Change probabilities to 0, 1
pred_train_PCE <- ifelse(pred_train_PCE > 0.2706511, 1, 0)
# Test set results
pred_test_PCE <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
# Change probabilities to 0, 1
pred_test_PCE <- ifelse(pred_test_PCE > 0.2706511, 1, 0)
train_pred_PCE <- factor(pred_train_PCE, levels = c(0, 1))
test_pred_PCE <- factor(pred_test_PCE, levels = c(0, 1))
# Building Confusion Matrices
results_PCE_train <- confusionMatrix(data=train_df_PCE$NegOutcome, reference=train_pred_PCE, positive = "1")
print(results_PCE_train)
results_PCE_test <- confusionMatrix(data=test_df_PCE$NegOutcome, reference=test_pred_PCE, positive = "1")
print(results_PCE_test)
# for our purposes, we want to optimize sensitivity
Accuracy <- c(results_PCE_train$overall[['Accuracy']] , results_PCE_test$overall[['Accuracy']])
Sensitivity <- c(results_PCE_train$byClass[['Sensitivity']] , results_PCE_test$byClass[['Sensitivity']])
Precision <- c(results_PCE_train$byClass[['Precision']] , results_PCE_test$byClass[['Precision']])
Specificity <- c(results_PCE_train$byClass[['Specificity']] , results_PCE_test$byClass[['Specificity']])
F1 <- c(results_PCE_train$byClass[['F1']] , results_PCE_test$byClass[['F1']])
df <- data.frame(Accuracy, F1, Sensitivity, Precision, Specificity)
row.names(df) <- c('Training Set', 'Testing Set')
df$PCE <- rownames(df)
# Order the columns to have the index column first
df <- df[, c("PCE", "Accuracy", "F1", "Sensitivity", "Precision","Specificity")]
# Create the flextable
print(flextable(df))
pred_test_PCE <- predict(logr_model_PCE, newdata = test_df_PCE, type="response")
# create ROC object
roc_object <- roc(test_df_PCE$NegOutcome, pred_test_PCE)
# calculate area under curve
auc(roc_object)
plot(roc_object, main = "ROC Curve", col = "#1c61b6", lwd = 2, print.thres=TRUE, print.auc=TRUE)
# code for optimal threshold value
# the threshold printed right now is with the highest sum sensitivity + specificity is plotted
logr_model_SDOH <- glm(NegOutcome ~., family=binomial, data=train_df_SDOH)
summary(logr_model_SDOH)
tidy_model <- tidy(logr_model_SDOH)
ft <- flextable(tidy_model)
# Apply custom formatting to different columns
ft <- set_formatter(ft,
estimate = function(x) format(x, digits = 4, nsmall = 4),    # 4 decimal places
std.error = function(x) format(x, digits = 4, nsmall = 4),
statistic = function(x) format(x, digits = 3, nsmall = 3),
p.value = format_pvalue,     # 4 decimal places for p-values
conf.low = function(x) format(x, digits = 4, nsmall = 4),
conf.high = function(x) format(x, digits = 4, nsmall = 4)
)
print(ft)
odds_ratios <- exp(coef(logr_model_SDOH))  # Computes the odds ratios for the coefficients
print(odds_ratios)
View(train_df_SDOH)
tidied_model <- tidy(logr_model_SDOH)
# Calculate odds ratios and determine the top 10 predictors based on their impact
top_predictors_or <- tidied_model %>%
mutate(OddsRatio = exp(estimate),
OR_AbsImpact = abs(log(OddsRatio))) %>%  # Using log odds to find the strongest predictors
arrange(desc(OR_AbsImpact)) %>%
slice(1:10)
# Display the top 10 predictors using odds ratios with knitr::kable
kable(top_predictors_or, format = "html", digits = 3,
caption = "Top 10 Key Predictors by Odds Ratios in Logistic Regression Model")
tidied_model <- tidy(logr_model_SDOH)
# Calculate odds ratios and determine the top 10 predictors based on their impact
top_predictors_or <- tidied_model %>%
mutate(OddsRatio = exp(estimate),
OR_AbsImpact = abs(log(OddsRatio))) %>%  # Using log odds to find the strongest predictors
arrange(desc(OR_AbsImpact)) %>%
slice(1:10)
# Display the top 10 predictors using odds ratios with knitr::kable
kable(top_predictors_or, format = "html", digits = 3,
caption = "Top 10 Key Predictors by Odds Ratios in SDOH Model")
tidied_model <- tidy(logr_model_SDOH)
top_increasing_predictors <- tidied_model %>%
mutate(OddsRatio = exp(estimate)) %>%
filter(estimate > 0) %>%  # Filtering to keep only positive coefficients
arrange(desc(OddsRatio)) %>%  # Sort by descending odds ratios
slice(1:10)
# Display these top predictors using knitr::kable
kable(top_increasing_predictors, format = "html", digits = 3,
caption = "Top 10 Predictors Increasing Likelihood of Neg Outcome: SDOH")
tidied_model <- tidy(logr_model_SDOH)
top_increasing_predictors <- tidied_model %>%
mutate(OddsRatio = exp(estimate)) %>%
filter(estimate > 0) %>%  # Filtering to keep only positive coefficients
arrange(desc(OddsRatio)) %>%  # Sort by descending odds ratios
slice(1:20)
# Display these top predictors using knitr::kable
kable(top_increasing_predictors, format = "html", digits = 3,
caption = "Top 20 Predictors Increasing Likelihood of Neg Outcome: SDOH")
tidied_model <- tidy(logr_model_SDOH)
top_increasing_predictors <- tidied_model %>%
mutate(OddsRatio = exp(estimate)) %>%
filter(estimate > 0) %>%  # Filtering to keep only positive coefficients
arrange(desc(OddsRatio)) %>%  # Sort by descending odds ratios
slice(1:20)
# Display these top predictors using knitr::kable
kable(top_increasing_predictors, format = "html", digits = 3,
caption = "Top 25 Predictors Increasing Likelihood of Neg Outcome: SDOH")
tidied_model <- tidy(logr_model_SDOH)
top_increasing_predictors <- tidied_model %>%
mutate(OddsRatio = exp(estimate)) %>%
filter(estimate > 0) %>%  # Filtering to keep only positive coefficients
arrange(desc(OddsRatio)) %>%  # Sort by descending odds ratios
slice(1:30)
# Display these top predictors using knitr::kable
kable(top_increasing_predictors, format = "html", digits = 3,
caption = "Top 25 Predictors Increasing Likelihood of Neg Outcome: SDOH")
tidied_model <- tidy(logr_model_SDOH)
top_increasing_predictors <- tidied_model %>%
mutate(OddsRatio = exp(estimate)) %>%
filter(estimate > 0) %>%  # Filtering to keep only positive coefficients
arrange(desc(OddsRatio)) %>%  # Sort by descending odds ratios
slice(1:30)
# Display these top predictors using knitr::kable
kable(top_increasing_predictors, format = "html", digits = 3,
caption = "Top 10 Predictors Increasing Likelihood of Neg Outcome: SDOH")
tidied_model <- tidy(logr_model_SDOH)
top_increasing_predictors <- tidied_model %>%
mutate(OddsRatio = exp(estimate)) %>%
filter(estimate > 0) %>%  # Filtering to keep only positive coefficients
arrange(desc(OddsRatio)) %>%  # Sort by descending odds ratios
slice(1:10)
# Display these top predictors using knitr::kable
kable(top_increasing_predictors, format = "html", digits = 3,
caption = "Top 10 Predictors Increasing Likelihood of Neg Outcome: SDOH")
